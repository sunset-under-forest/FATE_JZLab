# 一、Fedcon说明
1. 此文件夹将federatedml中的贡献度算法Fedcon设计部分打包出来，方便审阅；
2. 需要使用时，请将文件中的内容替换到对应的文件夹下（事实上，文件已经全部在fedratedml对应的位置替换完成。您可以直接替换federatedml完成使用。）

# 二、Fedcon理论分析

为了处理数据非独立同分布的情况，本项目将提供第二种方案：<u>从本地模型更新和全局模型汇聚两个角度出发</u>，设计一种面向数据分布不平衡问题的<mark>**基于贡献度选择的模型聚合算法**</mark>。该种方案旨在免去数据预处理阶段造成的通信问题。
基于贡献度选择的模型聚合算法主要由算法$Update_{global}$、$Update_{local}$和贡献度计算算法$Con$构成。具体流程如下：

1. **计算客户端贡献度**
为计算每个客户端对模型更新的贡献度，中心服务器首先计算各模型在验证时的损失值，记为$L^{t-1} = \{L_1^{t-1}, L_2^{t-1}, ... , L_N^{t-1}\}$。随后，针对每一个节点的损失值，计算其在全局更新中的贡献度：$$ Con_n^{t-1} = \frac{1}{L_n^{t-1}} / \sum_{i=1}^N \frac{1}{L_i^{t-1}} $$其中，$L_n^{t-1}$表示第n个用户在第$t-1$轮中模型的损失值。为了表征损失值越小，贡献越大，采用了倒数的方式进行计算。随后，中心服务器将贡献度即当前全局模型分配给参与本轮次模型训练的节点$C_1，C_2，...，C_n$。

2. **基于贡献度进行模型更新**：
更新本地模型时，每个客户端$C_i$首先需要计算当前模型下得到的损失函数$L_i^t$。随后，对本地模型进行更新如下：$$ \theta_i^t=\theta_i^t-a \cdot \nabla L_i^t $$ 其中，α作为自适应学习率动态调整模型更新的幅度，其与贡献度$Con_i^{t-1}$相关，表达式如下：$$ a=\frac{\eta}{\sqrt{\operatorname{Con}_i^{t-1}+\epsilon}} $$ $\varepsilon$ 为一个极小值，用以避免分母为0的情况。由公式可以看出，当节点的贡献度较低时，正则项较大，对模型更新有着正向激励作用；而节点贡献度较大时，正则项较小，从而对模型更新起到限制的作用。

3. **在中心服务器，进行基于客户端贡献度的参数聚合算法**$Update\_global$：
最后，在中心服务器进行参数聚合，这一步同样与客户端贡献度相关，聚合算法如下：$$ \theta^{t+1} = \sum_{i=1}^N Con_i^t \theta_i^t $$

至此，当前轮次的模型更新完毕。其中，**客户端贡献度$Con$起着重要的作用**。本项目的主要工作之一便是针对客户端贡献度$Con$和本地模型更新算法进行进一步的调整，以更加适应Non-IID的数据分布情况。